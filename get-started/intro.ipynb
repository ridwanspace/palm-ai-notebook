{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is LLMs and PalM?\n",
    "\n",
    "This document provides an overview of large language models (LLMs) and Google's next-generation LLM, PaLM 2. LLMs are deep learning models trained on massive datasets of text. PaLM 2 excels at tasks like advanced reasoning, translation, and code generation. It builds on Google's legacy of breakthrough research in machine learning and responsible AI. LLMs are created using unsupervised learning, where the model learns to predict the next word in a sentence given the preceding words. This enables the model to generate coherent, fluent text resembling human writing. The model's large size allows it to learn complex patterns and relationships in language and generate high-quality text for various applications.\n",
    "\n",
    "### Available Models\n",
    "\n",
    "Vertex AI PaLM API models\n",
    "The Vertex AI PaLM API enables you to test, customize, and deploy instances of Googleâ€™s large language models (LLM) called as PaLM, so that you can leverage the capabilities of PaLM in your applications.\n",
    "\n",
    "Model naming scheme\n",
    "Foundation model names have three components: use case, model size, and version number. The naming convention is in the format:\n",
    "`<use case>-<model size>@<version number>`\n",
    "\n",
    "For example, _text-bison@001_ represents the Bison text model, version _001_.\n",
    "\n",
    "The model sizes are as follows:\n",
    "\n",
    "* __Bison__: The best value in terms of capability and cost.\n",
    "* __Gecko__: The smallest and cheapest model for simple tasks.\n",
    "\n",
    "Available models\n",
    "The Vertex AI PaLM API currently supports five models:\n",
    "\n",
    "* `text-bison@001` : Fine-tuned to follow natural language instructions and is suitable for a variety of language tasks.\n",
    "\n",
    "* `chat-bison@001` : Fine-tuned for multi-turn conversation use cases like building a chatbot.\n",
    "\n",
    "* `textembedding-gecko@001` : Returns model embeddings for text inputs.\n",
    "\n",
    "* `code-bison@001`: A model fine-tuned to generate code based on a natural language description of the desired code. For example, it can generate a unit test for a function.\n",
    "\n",
    "* `code-gecko@001`: A model fine-tuned to suggest code completion based on the context in code that's written.\n",
    "\n",
    "* `codechat-bison@001`: A model fine-tuned for chatbot conversations that help with code-related questions.\n",
    "\n",
    "You can find more information about the properties of these foundational models in the [Generative AI Studio documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models#foundation_models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import vertexai\n",
    "from IPython.display import Markdown, display\n",
    "from google.oauth2 import service_account\n",
    "from dotenv import load_dotenv\n",
    "from vertexai.language_models import TextGenerationModel, \\\n",
    "                                     TextEmbeddingModel, \\\n",
    "                                     ChatModel, \\\n",
    "                                     InputOutputTextPair, \\\n",
    "                                     CodeGenerationModel, \\\n",
    "                                     CodeChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate service account (authentication)\n",
    "json_path = '../../llm-ai.json' # replace with your own service account\n",
    "credentials = service_account.Credentials.from_service_account_file(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Vertex AI\n",
    "load_dotenv()\n",
    "vertexai.init(project=os.environ[\"PROJECT_ID\"], # replace with your own project\n",
    "              credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text generation with `text-bison@001`\n",
    "\n",
    "The text generation model from PaLM API that you will use in this notebook is text-bison@001. It is fine-tuned to follow natural language instructions and is suitable for a variety of language tasks, such as:\n",
    "\n",
    "* Classification\n",
    "* Sentiment analysis\n",
    "* Entity extraction\n",
    "* Extractive question-answering\n",
    "* Summarization\n",
    "* Re-writing text in a different style\n",
    "* Ad copy generation\n",
    "* Concept ideation\n",
    "* Concept simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hello PaLM__\n",
    "\n",
    "Create the first prompt and send it to the text generation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaLM AI (Pathways Language Model) is a large language model from Google AI. It was trained on a massive dataset of text and code, and it can understand and generate human language in a variety of ways. PaLM AI is still under development, but it has already been shown to be capable of impressive feats, such as writing different kinds of creative text, translating languages, answering your questions, and writing different kinds of creative text.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is PaLM AI?\"\n",
    "\n",
    "response = generation_model.predict(prompt=prompt)\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
