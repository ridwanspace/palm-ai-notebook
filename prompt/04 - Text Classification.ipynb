{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Generative models like PaLM 2 are powerful language models used for various natural language processing (NLP) tasks. One of those is text classification, which involves assigning one or more categories to a given piece of text. Although text classification can be done using traditional NLP techniques, LLMs can perform classification by providing prompts (as opposed to domain-specific labeled data), which can accelerate the time it takes to build a text classification solution. Classification models based on LLMs can be further tuned with many examples via custom model training, but that is beyond the scope of this notebook.\n",
    "\n",
    "In this notebook, we will explore how to do text classification using prompts with the PaLM API. Learn more about classification prompts in the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/text/classification-prompts).\n",
    "\n",
    "## Objective\n",
    "By the end of the notebook, we should be able to use a large language model to perform various classification tasks, including:\n",
    "\n",
    "* Zero-shot prompting text classification\n",
    "* Few-shot prompting text classification\n",
    "* Common tasks:\n",
    "* Sentiment analysis\n",
    "* Topic classification\n",
    "* Spam detection\n",
    "* Intent recognition\n",
    "* Language identification\n",
    "* Toxicity detection\n",
    "* Emotion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import vertexai\n",
    "from IPython.display import Markdown, display\n",
    "from google.oauth2 import service_account\n",
    "from dotenv import load_dotenv\n",
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate service account (authentication)\n",
    "json_path = '../llm-ai.json' # replace with your own service account\n",
    "credentials = service_account.Credentials.from_service_account_file(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Vertex AI\n",
    "load_dotenv()\n",
    "vertexai.init(project=os.environ[\"PROJECT_ID\"], # replace with your own project\n",
    "              credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification\n",
    "\n",
    "In the section below, you will explore zero-shot prompting, few-shot prompting, and some common types of text classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Zero-shot prompting\n",
    "Zero-shot prompting is where we do not provide examples with labels, and rely on the LLM to make the classification on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The text is about a furry animal with a long tail and big eyes. It is likely to be a dog or a cat."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Classify the following:\\n\n",
    "text: \"I saw a furry animal in the park today with a long tail and big eyes.\"\n",
    "label: dogs, cats\n",
    "\"\"\"\n",
    "\n",
    "label = generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    "\n",
    "# you may use print instead of display\n",
    "display(\n",
    "    Markdown(label)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Few-shot prompting\n",
    "\n",
    "With few-shot prompting, we provide examples to the PaLM model and expect it to predict classes based on the provided examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "entertainment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What is the topic for a given news headline? \\n\n",
    "- business \\n\n",
    "- entertainment \\n\n",
    "- health \\n\n",
    "- sports \\n\n",
    "- technology \\n\\n\n",
    "\n",
    "Text: Pixel 7 Pro Expert Hands On Review. \\n\n",
    "The answer is: technology \\n\n",
    "\n",
    "Text: Quit smoking? \\n\n",
    "The answer is: health \\n\n",
    "\n",
    "Text: Birdies or bogeys? Top 5 tips to hit under par \\n\n",
    "The answer is: sports \\n\n",
    "\n",
    "Text: Relief from local minimum-wage hike looking more remote \\n\n",
    "The answer is: business \\n\n",
    "\n",
    "Text: You won't guess who just arrived in Bari, Italy for the movie premiere. \\n\n",
    "The answer is:\n",
    "\"\"\"\n",
    "\n",
    "answer = generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    "\n",
    "display(\n",
    "    Markdown(answer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other classification examples**\n",
    "Explore some more common text classification prompts below, which are all based on zero-shot prompts. We can also turn some of these into few-shot prompts by providing our own custom examples of text and the associated output classes.\n",
    "\n",
    "### 3. Topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "politics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Classify a piece of text into one of several predefined topics, such as sports, politics, or entertainment. \\n\n",
    "text: President Biden will be visiting India in the month of March to discuss a few opportunites. \\n\n",
    "class:\n",
    "\"\"\"\n",
    "\n",
    "topic = generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    "\n",
    "display(\n",
    "    Markdown(topic)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "spam"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Given an email, classify it as spam or not spam. \\n\n",
    "email: hi user, \\n\n",
    "      you have been selected as a winner of the lotery and can win upto 1 million dollar. \\n\n",
    "      kindly share your bank details and we can proceed from there. \\n\\n\n",
    "\n",
    "      from, \\n\n",
    "      US Official Lottry Depatmint\n",
    "\"\"\"\n",
    "\n",
    "detect = generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    "\n",
    "display(\n",
    "    Markdown(detect)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Intent recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "making a reservation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Given a user's input, classify their intent, such as \"finding information\", \"making a reservation\", or \"placing an order\". \\n\n",
    "user input: Hi, can you please book a table for two at Juan for May 1?\n",
    "\"\"\"\n",
    "\n",
    "intent = generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    "\n",
    "display(\n",
    "    Markdown(intent)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Language identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Turkish"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Given a piece of text, classify the language it is written in. \\n\n",
    "text: Selam nasÄ±l gidiyor?\n",
    "language:\n",
    "\"\"\"\n",
    "\n",
    "language = generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    "\n",
    "display(\n",
    "    Markdown(language)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Toxicity detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Non-toxic"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Given a piece of text, classify it as toxic or non-toxic. \\n\n",
    "text: i love sunny days\n",
    "\"\"\"\n",
    "\n",
    "toxicity = generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    "\n",
    "display(\n",
    "    Markdown(toxicity)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Emotion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "happiness"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Given a piece of text, classify the emotion it conveys, such as happiness, or anger. \\n\n",
    "text: I'm still so delighted from yesterday's news\n",
    "\"\"\"\n",
    "\n",
    "emotion = generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    "\n",
    "display(\n",
    "    Markdown(emotion)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We can evaluate the outputs of the text classification task if the ground truth classes are available. To showcase how this works, start by creating a simple dataframe with product reviews and the ground truth sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment_groundtruth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love this product. it does have everything i am looking for!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all i can say is that you will be happy after buying this product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its way too expensive and not worth the price</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am feeling okay. its neither good nor too bad.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              review  \\\n",
       "0     i love this product. it does have everything i am looking for!   \n",
       "1  all i can say is that you will be happy after buying this product   \n",
       "2                      its way too expensive and not worth the price   \n",
       "3                   i am feeling okay. its neither good nor too bad.   \n",
       "\n",
       "  sentiment_groundtruth  \n",
       "0              positive  \n",
       "1              positive  \n",
       "2              negative  \n",
       "3               neutral  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = {\n",
    "    \"review\": [\n",
    "        \"i love this product. it does have everything i am looking for!\",\n",
    "        \"all i can say is that you will be happy after buying this product\",\n",
    "        \"its way too expensive and not worth the price\",\n",
    "        \"i am feeling okay. its neither good nor too bad.\",\n",
    "    ],\n",
    "    \"sentiment_groundtruth\": [\"positive\", \"positive\", \"negative\", \"neutral\"],\n",
    "}\n",
    "\n",
    "review_data_df = pd.DataFrame(review_data)\n",
    "review_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data with reviews and sentiments as ground truth labels, you can call the text generation model to each review row using the `apply` function. Each row will use the prompt in the `review` column to predict the sentiment using the PaLM API, and store the results in `sentiment_prediction` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment_groundtruth</th>\n",
       "      <th>sentiment_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love this product. it does have everything i am looking for!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all i can say is that you will be happy after buying this product</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its way too expensive and not worth the price</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am feeling okay. its neither good nor too bad.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              review  \\\n",
       "0     i love this product. it does have everything i am looking for!   \n",
       "1  all i can say is that you will be happy after buying this product   \n",
       "2                      its way too expensive and not worth the price   \n",
       "3                   i am feeling okay. its neither good nor too bad.   \n",
       "\n",
       "  sentiment_groundtruth sentiment_prediction  \n",
       "0              positive             positive  \n",
       "1              positive             positive  \n",
       "2              negative             negative  \n",
       "3               neutral              neutral  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentiment(row):\n",
    "    prompt = f\"\"\"Classify the sentiment of the following review as \"positive\", \"neutral\" and \"negative\". \\n\\n\n",
    "                review: {row} \\n\n",
    "                sentiment:\n",
    "              \"\"\"\n",
    "    response = generation_model.predict(prompt=prompt).text\n",
    "    return response\n",
    "\n",
    "\n",
    "review_data_df[\"sentiment_prediction\"] = review_data_df[\"review\"].apply(get_sentiment)\n",
    "review_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we can call the `classification_report` function from [sklearn](https://scikit-learn.org/stable/) to measure the accuracy and other classification metrics by passing ground truth sentiments `sentiment_groundtruth` and predicted sentiment `sentiment_prediction`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "              precision    recall  f1-score   support\n",
       "\n",
       "    negative       1.00      1.00      1.00         1\n",
       "     neutral       1.00      1.00      1.00         1\n",
       "    positive       1.00      1.00      1.00         2\n",
       "\n",
       "    accuracy                           1.00         4\n",
       "   macro avg       1.00      1.00      1.00         4\n",
       "weighted avg       1.00      1.00      1.00         4\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "display(\n",
    "        Markdown(\n",
    "        classification_report(\n",
    "            review_data_df[\"sentiment_groundtruth\"], review_data_df[\"sentiment_prediction\"]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
